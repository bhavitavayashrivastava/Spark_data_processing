{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('C:\\\\Users\\\\admin\\\\Desktop\\\\spark-data\\\\Fraud_Data.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 'signup_time',\n",
       " 'purchase_time',\n",
       " 'purchase_value',\n",
       " 'device_id',\n",
       " 'source',\n",
       " 'browser',\n",
       " 'sex',\n",
       " 'age',\n",
       " 'ip_address',\n",
       " 'is_fraud']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id', 'signup_time']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'source'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.col('source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'source'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.expr(\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[source: string, browser: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('source','browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) FileScan csv [source#15,browser#16] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/admin/Desktop/spark-data/Fraud_Data.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<source:string,browser:string>\n"
     ]
    }
   ],
   "source": [
    "df.select('source','browser').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|source|browser|\n",
      "+------+-------+\n",
      "|   SEO| Chrome|\n",
      "|   Ads| Chrome|\n",
      "|   SEO|  Opera|\n",
      "|   SEO| Safari|\n",
      "|   Ads| Safari|\n",
      "+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('source','browser').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|Source|Browser|\n",
      "+------+-------+\n",
      "|   SEO| Chrome|\n",
      "|   Ads| Chrome|\n",
      "|   SEO|  Opera|\n",
      "|   SEO| Safari|\n",
      "|   Ads| Safari|\n",
      "+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.col('source').alias('Source'),F.col('browser').alias('Browser')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, signup_time: timestamp, purchase_time: timestamp, purchase_value: int, device_id: string, source: string, browser: string, sex: string, age: int, ip_address: double, is_fraud: int]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|Source|browser|\n",
      "+------+-------+\n",
      "|   SEO| Chrome|\n",
      "|   ADS| Chrome|\n",
      "|   SEO|  Opera|\n",
      "|   SEO| Safari|\n",
      "|   ADS| Safari|\n",
      "+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('source','browser').withColumn('Source',F.upper(F.col('source'))).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| dept|salary|\n",
      "+---+-----+------+\n",
      "|  1|sales|  2700|\n",
      "|  2|admin|  3700|\n",
      "|  3|sales|  4700|\n",
      "|  4|admin|  1500|\n",
      "|  5|  dev|  3000|\n",
      "|  6|  dev|  2700|\n",
      "|  7|sales|  3200|\n",
      "|  8|  dev|  1900|\n",
      "|  9|  dev|  4500|\n",
      "| 10|  dev|  4000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = [\n",
    "    (1,'sales',2700),\n",
    "    (2,'admin',3700),\n",
    "    (3,'sales',4700),\n",
    "    (4,'admin',1500),\n",
    "    (5,'dev',3000),\n",
    "    (6,'dev',2700),\n",
    "    (7,'sales',3200),\n",
    "    (8,'dev',1900),\n",
    "    (9,'dev',4500),\n",
    "    (10,'dev',4000)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "data = spark.createDataFrame(l,schema=['id','dept','salary'])\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------------+----------------+\n",
      "| dept|         list_salary|    average_salary|summation_salary|\n",
      "+-----+--------------------+------------------+----------------+\n",
      "|  dev|[3000, 2700, 1900...|            3220.0|           16100|\n",
      "|sales|  [2700, 4700, 3200]|3533.3333333333335|           10600|\n",
      "|admin|        [3700, 1500]|            2600.0|            5200|\n",
      "+-----+--------------------+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = data.groupBy('dept').agg(\n",
    "F.expr('collect_list(salary)').alias('list_salary'),\n",
    "F.expr('avg(salary)').alias('average_salary'),\n",
    "F.expr('sum(salary)').alias('summation_salary')\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+--------------------+------------------+------------+\n",
      "| id| dept|salary|         list_salary|    average_salary|total_salary|\n",
      "+---+-----+------+--------------------+------------------+------------+\n",
      "|  8|  dev|  1900|              [1900]|            1900.0|        1900|\n",
      "|  6|  dev|  2700|        [1900, 2700]|            2300.0|        4600|\n",
      "|  5|  dev|  3000|  [1900, 2700, 3000]|2533.3333333333335|        7600|\n",
      "| 10|  dev|  4000|[1900, 2700, 3000...|            2900.0|       11600|\n",
      "|  9|  dev|  4500|[1900, 2700, 3000...|            3220.0|       16100|\n",
      "|  1|sales|  2700|              [2700]|            2700.0|        2700|\n",
      "|  7|sales|  3200|        [2700, 3200]|            2950.0|        5900|\n",
      "|  3|sales|  4700|  [2700, 3200, 4700]|3533.3333333333335|       10600|\n",
      "|  4|admin|  1500|              [1500]|            1500.0|        1500|\n",
      "|  2|admin|  3700|        [1500, 3700]|            2600.0|        5200|\n",
      "+---+-----+------+--------------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# windowspec = Window.partitionBy('dept')\n",
    "windowspec = Window.partitionBy('dept').orderBy(F.asc('salary'))\n",
    "\n",
    "\n",
    "df = data.withColumn('list_salary',F.collect_list(F.col('salary')).over(windowspec))\\\n",
    ".withColumn('average_salary',F.avg(F.col('salary')).over(windowspec))\\\n",
    ".withColumn('total_salary',F.sum(F.col('salary')).over(windowspec))\n",
    "\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
