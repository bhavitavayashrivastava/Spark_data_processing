{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('ratings.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows :100836,\n",
      "Columns : 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rows :{df.count()},\\nColumns : {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|     4|964982703|\n",
      "|     1|      3|     4|964981247|\n",
      "|     1|      6|     4|964982224|\n",
      "|     1|     47|     5|964983815|\n",
      "|     1|     50|     5|964982931|\n",
      "|     1|     70|     3|964982400|\n",
      "|     1|    101|     5|964980868|\n",
      "|     1|    110|     4|964982176|\n",
      "|     1|    151|     5|964984041|\n",
      "|     1|    157|     5|964984100|\n",
      "|     1|    163|     5|964983650|\n",
      "|     1|    216|     5|964981208|\n",
      "|     1|    223|     3|964980985|\n",
      "|     1|    231|     5|964981179|\n",
      "|     1|    235|     4|964980908|\n",
      "|     1|    260|     5|964981680|\n",
      "|     1|    296|     3|964982967|\n",
      "|     1|    316|     3|964982310|\n",
      "|     1|    333|     5|964981179|\n",
      "|     1|    349|     4|964982563|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userId', 'string'),\n",
       " ('movieId', 'string'),\n",
       " ('rating', 'string'),\n",
       " ('timestamp', 'string')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId movieId rating  timestamp\n",
       "0      1       1      4  964982703\n",
       "1      1       3      4  964981247\n",
       "2      1       6      4  964982224\n",
       "3      1      47      5  964983815\n",
       "4      1      50      5  964982931"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100836, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   userId     100836 non-null  object\n",
      " 1   movieId    100836 non-null  object\n",
      " 2   rating     100836 non-null  object\n",
      " 3   timestamp  100836 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_pandas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.createDataFrame(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|     4|964982703|\n",
      "|     1|      3|     4|964981247|\n",
      "|     1|      6|     4|964982224|\n",
      "|     1|     47|     5|964983815|\n",
      "|     1|     50|     5|964982931|\n",
      "|     1|     70|     3|964982400|\n",
      "|     1|    101|     5|964980868|\n",
      "|     1|    110|     4|964982176|\n",
      "|     1|    151|     5|964984041|\n",
      "|     1|    157|     5|964984100|\n",
      "|     1|    163|     5|964983650|\n",
      "|     1|    216|     5|964981208|\n",
      "|     1|    223|     3|964980985|\n",
      "|     1|    231|     5|964981179|\n",
      "|     1|    235|     4|964980908|\n",
      "|     1|    260|     5|964981680|\n",
      "|     1|    296|     3|964982967|\n",
      "|     1|    316|     3|964982310|\n",
      "|     1|    333|     5|964981179|\n",
      "|     1|    349|     4|964982563|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|     4|964982703|\n",
      "|     1|      3|     4|964981247|\n",
      "|     1|      6|     4|964982224|\n",
      "|     1|     47|     5|964983815|\n",
      "|     1|     50|     5|964982931|\n",
      "|     1|     70|     3|964982400|\n",
      "|     1|    101|     5|964980868|\n",
      "|     1|    110|     4|964982176|\n",
      "|     1|    151|     5|964984041|\n",
      "|     1|    157|     5|964984100|\n",
      "|     1|    163|     5|964983650|\n",
      "|     1|    216|     5|964981208|\n",
      "|     1|    223|     3|964980985|\n",
      "|     1|    231|     5|964981179|\n",
      "|     1|    235|     4|964980908|\n",
      "|     1|    260|     5|964981680|\n",
      "|     1|    296|     3|964982967|\n",
      "|     1|    316|     3|964982310|\n",
      "|     1|    333|     5|964981179|\n",
      "|     1|    349|     4|964982563|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+--------------------------------------+\n",
      "|userId|movieId|rating|timestamp|CASE WHEN (rating = 3) THEN rating END|\n",
      "+------+-------+------+---------+--------------------------------------+\n",
      "|     1|      1|     4|964982703|                                  null|\n",
      "|     1|      3|     4|964981247|                                  null|\n",
      "|     1|      6|     4|964982224|                                  null|\n",
      "|     1|     47|     5|964983815|                                  null|\n",
      "|     1|     50|     5|964982931|                                  null|\n",
      "|     1|     70|     3|964982400|                                     3|\n",
      "|     1|    101|     5|964980868|                                  null|\n",
      "|     1|    110|     4|964982176|                                  null|\n",
      "|     1|    151|     5|964984041|                                  null|\n",
      "|     1|    157|     5|964984100|                                  null|\n",
      "|     1|    163|     5|964983650|                                  null|\n",
      "|     1|    216|     5|964981208|                                  null|\n",
      "|     1|    223|     3|964980985|                                     3|\n",
      "|     1|    231|     5|964981179|                                  null|\n",
      "|     1|    235|     4|964980908|                                  null|\n",
      "|     1|    260|     5|964981680|                                  null|\n",
      "|     1|    296|     3|964982967|                                     3|\n",
      "|     1|    316|     3|964982310|                                     3|\n",
      "|     1|    333|     5|964981179|                                  null|\n",
      "|     1|    349|     4|964982563|                                  null|\n",
      "+------+-------+------+---------+--------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "df.select(col(\"*\"),when(col(\"rating\")==3,col(\"rating\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|rating|\n",
      "+------+\n",
      "|     3|\n",
      "|   4.5|\n",
      "|   2.5|\n",
      "|     5|\n",
      "|   3.5|\n",
      "|   0.5|\n",
      "|   1.5|\n",
      "|     1|\n",
      "|     4|\n",
      "|     2|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"rating\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|movieId|3 * rating|\n",
      "+-------+----------+\n",
      "|      1|      null|\n",
      "|      3|      null|\n",
      "|      6|      null|\n",
      "|     47|      null|\n",
      "|     50|      null|\n",
      "|     70|         3|\n",
      "|    101|      null|\n",
      "|    110|      null|\n",
      "|    151|      null|\n",
      "|    157|      null|\n",
      "|    163|      null|\n",
      "|    216|      null|\n",
      "|    223|         3|\n",
      "|    231|      null|\n",
      "|    235|      null|\n",
      "|    260|      null|\n",
      "|    296|         3|\n",
      "|    316|         3|\n",
      "|    333|      null|\n",
      "|    349|      null|\n",
      "+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"movieId\"),when(col(\"rating\")==3,col(\"rating\")).alias(\"3 * rating\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId', 'movieId', 'rating', 'timestamp']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+----------------+\n",
      "|userId|movieId|rating|timestamp|3 * movie rating|\n",
      "+------+-------+------+---------+----------------+\n",
      "|     1|      1|     4|964982703|            null|\n",
      "|     1|      3|     4|964981247|            null|\n",
      "|     1|      6|     4|964982224|            null|\n",
      "|     1|     47|     5|964983815|            null|\n",
      "|     1|     50|     5|964982931|            null|\n",
      "|     1|     70|     3|964982400|              70|\n",
      "|     1|    101|     5|964980868|            null|\n",
      "|     1|    110|     4|964982176|            null|\n",
      "|     1|    151|     5|964984041|            null|\n",
      "|     1|    157|     5|964984100|            null|\n",
      "|     1|    163|     5|964983650|            null|\n",
      "|     1|    216|     5|964981208|            null|\n",
      "|     1|    223|     3|964980985|             223|\n",
      "|     1|    231|     5|964981179|            null|\n",
      "|     1|    235|     4|964980908|            null|\n",
      "|     1|    260|     5|964981680|            null|\n",
      "|     1|    296|     3|964982967|             296|\n",
      "|     1|    316|     3|964982310|             316|\n",
      "|     1|    333|     5|964981179|            null|\n",
      "|     1|    349|     4|964982563|            null|\n",
      "+------+-------+------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"*\"),when(col(\"rating\")==3,col(\"movieId\")).alias(\"3 * movie rating\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|movieId|3* 4* rating|\n",
      "+-------+------------+\n",
      "|      1|           4|\n",
      "|      3|           4|\n",
      "|      6|           4|\n",
      "|     47|        null|\n",
      "|     50|        null|\n",
      "|     70|           3|\n",
      "|    101|        null|\n",
      "|    110|           4|\n",
      "|    151|        null|\n",
      "|    157|        null|\n",
      "|    163|        null|\n",
      "|    216|        null|\n",
      "|    223|           3|\n",
      "|    231|        null|\n",
      "|    235|           4|\n",
      "|    260|        null|\n",
      "|    296|           3|\n",
      "|    316|           3|\n",
      "|    333|        null|\n",
      "|    349|           4|\n",
      "+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"movieId\"),when(col(\"rating\")==3,col(\"rating\")).when(col(\"rating\")==4,col(\"rating\")).alias(\"3* 4* rating\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|movieId|3* 4* rating|\n",
      "+-------+------------+\n",
      "|      1|           4|\n",
      "|      3|           4|\n",
      "|      6|           4|\n",
      "|     47|           0|\n",
      "|     50|           0|\n",
      "|     70|           3|\n",
      "|    101|           0|\n",
      "|    110|           4|\n",
      "|    151|           0|\n",
      "|    157|           0|\n",
      "|    163|           0|\n",
      "|    216|           0|\n",
      "|    223|           3|\n",
      "|    231|           0|\n",
      "|    235|           4|\n",
      "|    260|           0|\n",
      "|    296|           3|\n",
      "|    316|           3|\n",
      "|    333|           0|\n",
      "|    349|           4|\n",
      "+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"movieId\"),when(col(\"rating\")==3,col(\"rating\")).when(col(\"rating\")==4,col(\"rating\")).otherwise(\"0\").alias(\"3* 4* rating\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|rating|* rating count|\n",
      "+------+--------------+\n",
      "|     3|         20047|\n",
      "|   4.5|          8551|\n",
      "|   2.5|          5550|\n",
      "|     5|         13211|\n",
      "|   3.5|         13136|\n",
      "|   0.5|          1370|\n",
      "|   1.5|          1791|\n",
      "|     1|          2811|\n",
      "|     4|         26818|\n",
      "|     2|          7551|\n",
      "+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('rating').agg(count(\"*\").alias(\"* rating count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId', 'movieId', 'rating', 'timestamp']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|userId|rating_cnt|\n",
      "+------+----------+\n",
      "|   296|         5|\n",
      "|   467|         5|\n",
      "|   125|         5|\n",
      "|   451|         5|\n",
      "|   124|         5|\n",
      "|   447|         5|\n",
      "|    51|         5|\n",
      "|   591|         5|\n",
      "|     7|         5|\n",
      "|   307|         5|\n",
      "|   475|         5|\n",
      "|   574|         5|\n",
      "|   169|         5|\n",
      "|   205|         5|\n",
      "|   334|       4.5|\n",
      "|   544|         5|\n",
      "|   577|         5|\n",
      "|   581|         5|\n",
      "|   272|         5|\n",
      "|   442|       2.5|\n",
      "+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df.groupBy('userId').agg(F.max('rating').alias('rating_cnt')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|userId|max_rating|\n",
      "+------+----------+\n",
      "|   296|         5|\n",
      "|   467|         5|\n",
      "|   125|         5|\n",
      "|   451|         5|\n",
      "|   124|         5|\n",
      "|   447|         5|\n",
      "|    51|         5|\n",
      "|   591|         5|\n",
      "|     7|         5|\n",
      "|   307|         5|\n",
      "|   475|         5|\n",
      "|   574|         5|\n",
      "|   169|         5|\n",
      "|   205|         5|\n",
      "|   334|       4.5|\n",
      "|   544|         5|\n",
      "|   577|         5|\n",
      "|   581|         5|\n",
      "|   272|         5|\n",
      "|   442|       2.5|\n",
      "+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select userId, max(rating) as max_rating from table group by userId').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   296|   27|\n",
      "|   467|   22|\n",
      "|   125|  360|\n",
      "|   451|   34|\n",
      "|     7|  152|\n",
      "|    51|  359|\n",
      "|   124|   50|\n",
      "|   447|   78|\n",
      "|   591|   54|\n",
      "|   307|  975|\n",
      "|   475|  155|\n",
      "|   574|   23|\n",
      "|   169|  269|\n",
      "|   205|   27|\n",
      "|   334|  154|\n",
      "|   544|   22|\n",
      "|   577|  161|\n",
      "|   581|   40|\n",
      "|   272|   31|\n",
      "|   442|   20|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select userId, count(*) as count from table group by userId\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+-------+-----+-------+--------+--------+---------+------+-------+--------------+-----+----------+------+\n",
      "|sl_no|gender|ssc_p|  ssc_b|hsc_p|  hsc_b|   hsc_s|degree_p| degree_t|workex|etest_p|specialisation|mba_p|    status|salary|\n",
      "+-----+------+-----+-------+-----+-------+--------+--------+---------+------+-------+--------------+-----+----------+------+\n",
      "|    1|     M|67.00| Others|91.00| Others|Commerce|   58.00| Sci&Tech|    No|     55|        Mkt&HR| 58.8|    Placed|270000|\n",
      "|    2|     M|79.33|Central|78.33| Others| Science|   77.48| Sci&Tech|   Yes|   86.5|       Mkt&Fin|66.28|    Placed|200000|\n",
      "|    3|     M|65.00|Central|68.00|Central|    Arts|   64.00|Comm&Mgmt|    No|     75|       Mkt&Fin| 57.8|    Placed|250000|\n",
      "|    4|     M|56.00|Central|52.00|Central| Science|   52.00| Sci&Tech|    No|     66|        Mkt&HR|59.43|Not Placed|  null|\n",
      "|    5|     M|85.80|Central|73.60|Central|Commerce|   73.30|Comm&Mgmt|    No|   96.8|       Mkt&Fin| 55.5|    Placed|425000|\n",
      "|    6|     M|55.00| Others|49.80| Others| Science|   67.25| Sci&Tech|   Yes|     55|       Mkt&Fin|51.58|Not Placed|  null|\n",
      "|    7|     F|46.00| Others|49.20| Others|Commerce|   79.00|Comm&Mgmt|    No|  74.28|       Mkt&Fin|53.29|Not Placed|  null|\n",
      "|    8|     M|82.00|Central|64.00|Central| Science|   66.00| Sci&Tech|   Yes|     67|       Mkt&Fin|62.14|    Placed|252000|\n",
      "|    9|     M|73.00|Central|79.00|Central|Commerce|   72.00|Comm&Mgmt|    No|  91.34|       Mkt&Fin|61.29|    Placed|231000|\n",
      "|   10|     M|58.00|Central|70.00|Central|Commerce|   61.00|Comm&Mgmt|    No|     54|       Mkt&Fin|52.21|Not Placed|  null|\n",
      "|   11|     M|58.00|Central|61.00|Central|Commerce|   60.00|Comm&Mgmt|   Yes|     62|        Mkt&HR|60.85|    Placed|260000|\n",
      "|   12|     M|69.60|Central|68.40|Central|Commerce|   78.30|Comm&Mgmt|   Yes|     60|       Mkt&Fin| 63.7|    Placed|250000|\n",
      "|   13|     F|47.00|Central|55.00| Others| Science|   65.00|Comm&Mgmt|    No|     62|        Mkt&HR|65.04|Not Placed|  null|\n",
      "|   14|     F|77.00|Central|87.00|Central|Commerce|   59.00|Comm&Mgmt|    No|     68|       Mkt&Fin|68.63|    Placed|218000|\n",
      "|   15|     M|62.00|Central|47.00|Central|Commerce|   50.00|Comm&Mgmt|    No|     76|        Mkt&HR|54.96|Not Placed|  null|\n",
      "|   16|     F|65.00|Central|75.00|Central|Commerce|   69.00|Comm&Mgmt|   Yes|     72|       Mkt&Fin|64.66|    Placed|200000|\n",
      "|   17|     M|63.00|Central|66.20|Central|Commerce|   65.60|Comm&Mgmt|   Yes|     60|       Mkt&Fin|62.54|    Placed|300000|\n",
      "|   18|     F|55.00|Central|67.00|Central|Commerce|   64.00|Comm&Mgmt|    No|     60|       Mkt&Fin|67.28|Not Placed|  null|\n",
      "|   19|     F|63.00|Central|66.00|Central|Commerce|   64.00|Comm&Mgmt|    No|     68|        Mkt&HR|64.08|Not Placed|  null|\n",
      "|   20|     M|60.00| Others|67.00| Others|    Arts|   70.00|Comm&Mgmt|   Yes|  50.48|       Mkt&Fin|77.89|    Placed|236000|\n",
      "+-----+------+-----+-------+-----+-------+--------+--------+---------+------+-------+--------------+-----+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_place = spark.read.csv('Placement_Data_Full_Class.csv',header=True)\n",
    "df_place.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sl_no', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('ssc_p', 'string'),\n",
       " ('ssc_b', 'string'),\n",
       " ('hsc_p', 'string'),\n",
       " ('hsc_b', 'string'),\n",
       " ('hsc_s', 'string'),\n",
       " ('degree_p', 'string'),\n",
       " ('degree_t', 'string'),\n",
       " ('workex', 'string'),\n",
       " ('etest_p', 'string'),\n",
       " ('specialisation', 'string'),\n",
       " ('mba_p', 'string'),\n",
       " ('status', 'string'),\n",
       " ('salary', 'string')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_place.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "df_place = df_place.withColumn('salary',df_place['salary'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sl_no', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('ssc_p', 'string'),\n",
       " ('ssc_b', 'string'),\n",
       " ('hsc_p', 'string'),\n",
       " ('hsc_b', 'string'),\n",
       " ('hsc_s', 'string'),\n",
       " ('degree_p', 'string'),\n",
       " ('degree_t', 'string'),\n",
       " ('workex', 'string'),\n",
       " ('etest_p', 'string'),\n",
       " ('specialisation', 'string'),\n",
       " ('mba_p', 'string'),\n",
       " ('status', 'string'),\n",
       " ('salary', 'int')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_place.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|   hsc_s|\n",
      "+--------+\n",
      "| Science|\n",
      "|Commerce|\n",
      "|    Arts|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_place.select('hsc_s').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+--------+\n",
      "|gender|   Arts|Commerce| Science|\n",
      "+------+-------+--------+--------+\n",
      "|     F|1006000| 6210000| 5614000|\n",
      "|     M| 486000|16496000|12909000|\n",
      "+------+-------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_place.groupBy('gender').pivot('hsc_s').sum('salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sl_no',\n",
       " 'gender',\n",
       " 'ssc_p',\n",
       " 'ssc_b',\n",
       " 'hsc_p',\n",
       " 'hsc_b',\n",
       " 'hsc_s',\n",
       " 'degree_p',\n",
       " 'degree_t',\n",
       " 'workex',\n",
       " 'etest_p',\n",
       " 'specialisation',\n",
       " 'mba_p',\n",
       " 'status',\n",
       " 'salary']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_place.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place = df_place.withColumn('ssc_p',df_place['ssc_p'].cast(IntegerType())).withColumn('hsc_p',df_place['hsc_p'].cast(IntegerType())).withColumn('degree_p',df_place['degree_p'].cast(IntegerType())).withColumn('etest_p',df_place['etest_p'].cast(IntegerType())).withColumn('mba_p',df_place['mba_p'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userId', 'string'),\n",
       " ('movieId', 'string'),\n",
       " ('rating', 'string'),\n",
       " ('timestamp', 'string')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sl_no', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('ssc_p', 'int'),\n",
       " ('ssc_b', 'string'),\n",
       " ('hsc_p', 'int'),\n",
       " ('hsc_b', 'string'),\n",
       " ('hsc_s', 'string'),\n",
       " ('degree_p', 'int'),\n",
       " ('degree_t', 'string'),\n",
       " ('workex', 'string'),\n",
       " ('etest_p', 'int'),\n",
       " ('specialisation', 'string'),\n",
       " ('mba_p', 'int'),\n",
       " ('status', 'string'),\n",
       " ('salary', 'int')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_place.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_place.rdd.map(lambda x: (x.gender,x.ssc_p,x.hsc_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('M', 67, 91), ('M', 79, 78), ('M', 65, 68), ('M', 56, 52), ('M', 85, 73), ('M', 55, 49), ('F', 46, 49), ('M', 82, 64), ('M', 73, 79), ('M', 58, 70)]\n"
     ]
    }
   ],
   "source": [
    "print(df1.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = ['gender','ssc_p','hsc_p']\n",
    "\n",
    "df2 = df_place.rdd.map(lambda x: (x.gender,x.ssc_p+2,x.hsc_p)).toDF(sch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+\n",
      "|gender|ssc_p|hsc_p|\n",
      "+------+-----+-----+\n",
      "|     M|   69|   91|\n",
      "|     M|   81|   78|\n",
      "|     M|   67|   68|\n",
      "|     M|   58|   52|\n",
      "|     M|   87|   73|\n",
      "|     M|   57|   49|\n",
      "|     F|   48|   49|\n",
      "|     M|   84|   64|\n",
      "|     M|   75|   79|\n",
      "|     M|   60|   70|\n",
      "|     M|   60|   61|\n",
      "|     M|   71|   68|\n",
      "|     F|   49|   55|\n",
      "|     F|   79|   87|\n",
      "|     M|   64|   47|\n",
      "|     F|   67|   75|\n",
      "|     M|   65|   66|\n",
      "|     F|   57|   67|\n",
      "|     F|   65|   66|\n",
      "|     M|   62|   67|\n",
      "+------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average = df_place.rdd.map(lambda x: (x.sl_no,x.gender,(x.ssc_p+x.hsc_p)/2)).toDF(['serial_no','gender','average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------+\n",
      "|serial_no|gender|average|\n",
      "+---------+------+-------+\n",
      "|        1|     M|   79.0|\n",
      "|        2|     M|   78.5|\n",
      "|        3|     M|   66.5|\n",
      "|        4|     M|   54.0|\n",
      "|        5|     M|   79.0|\n",
      "|        6|     M|   52.0|\n",
      "|        7|     F|   47.5|\n",
      "|        8|     M|   73.0|\n",
      "|        9|     M|   76.0|\n",
      "|       10|     M|   64.0|\n",
      "|       11|     M|   59.5|\n",
      "|       12|     M|   68.5|\n",
      "|       13|     F|   51.0|\n",
      "|       14|     F|   82.0|\n",
      "|       15|     M|   54.5|\n",
      "|       16|     F|   70.0|\n",
      "|       17|     M|   64.5|\n",
      "|       18|     F|   61.0|\n",
      "|       19|     F|   64.5|\n",
      "|       20|     M|   63.5|\n",
      "+---------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_average.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add = spark.read.csv('sample_address.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+--------------------+\n",
      "|Emp_Id|               Name|             Address|\n",
      "+------+-------------------+--------------------+\n",
      "|  1001|      Rahul Tewatia|220 Bapat street;...|\n",
      "|  1002|  Aarav Shrivastava|Abhyankar street;...|\n",
      "|  1003|     Harshad Badani|Abhyankar street;...|\n",
      "|  1004|      Deepak Saxena|Anand street;Mang...|\n",
      "|  1005|      Shalini Singh|Vip Road;Daya kun...|\n",
      "|  1006|  Manoj Shrivastava|Mandir Road;C-23 ...|\n",
      "|  1007|           MS Dhoni|Abhyankar street;...|\n",
      "|  1008|      Setu Upadhyay|Zuzuvadi Road;Zol...|\n",
      "|  1009|  Kiaan Shrivastava|Abhyankar street;...|\n",
      "|  1010|Paridhi Shrivastava|Abhyankar street;...|\n",
      "+------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_add.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col_name = F.split(df_add['Name'],' ')\n",
    "\n",
    "df_add = df_add.withColumn('First_name',split_col_name.getItem(0))\n",
    "df_add = df_add.withColumn('Surname',split_col_name.getItem(1))\n",
    "\n",
    "split_col_address = F.split(df_add['Address'],';')\n",
    "\n",
    "df_add = df_add.withColumn('Street',split_col_address.getItem(0))\n",
    "df_add = df_add.withColumn('Apartment',split_col_address.getItem(1))\n",
    "df_add = df_add.withColumn('Suburb',split_col_address.getItem(2))\n",
    "df_add = df_add.withColumn('City',split_col_address.getItem(3))\n",
    "df_add = df_add.withColumn('ZipCode',split_col_address.getItem(4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add = df_add.drop('Name','Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------+----------------+--------------------+------------+---------+-------+\n",
      "|Emp_Id|First_name|    Surname|          Street|           Apartment|      Suburb|     City|ZipCode|\n",
      "+------+----------+-----------+----------------+--------------------+------------+---------+-------+\n",
      "|  1001|     Rahul|    Tewatia|220 Bapat street|   Radhika Apartment|       Wakad|     Pune| 311057|\n",
      "|  1002|     Aarav|Shrivastava|Abhyankar street|shree Palace Apar...|    Dhantoli|   Nagpur| 440012|\n",
      "|  1003|   Harshad|     Badani|Abhyankar street|     shree Apartment|    Dhantoli|   Nagpur| 440012|\n",
      "|  1004|    Deepak|     Saxena|    Anand street|    Mangal Apartment|Rohini Nagar|     Kota| 450112|\n",
      "|  1005|   Shalini|      Singh|        Vip Road|    Daya kunj bangla|    MP Nagar|   Bhopal| 410256|\n",
      "|  1006|     Manoj|Shrivastava|     Mandir Road|   C-23 Kachnar City| Vijay Nagar| Jabalpur| 440057|\n",
      "|  1007|        MS|      Dhoni|Abhyankar street|shree Palace Apar...| Dhant Nagar|   Ranchi| 440612|\n",
      "|  1008|      Setu|   Upadhyay|   Zuzuvadi Road|      Zolo Hibiscous|  BTM Layout|Bangalore| 441012|\n",
      "|  1009|     Kiaan|Shrivastava|Abhyankar street|shree Palace Apar...|    Dhantoli|   Mumbai| 442012|\n",
      "|  1010|   Paridhi|Shrivastava|Abhyankar street|shree Palace Apar...|    Dhantoli|   Jaipur| 443012|\n",
      "+------+----------+-----------+----------------+--------------------+------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_add.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------+----------------+--------------------+-----------+--------+-------+\n",
      "|Emp_Id|First_name|    Surname|          Street|           Apartment|     Suburb|    City|ZipCode|\n",
      "+------+----------+-----------+----------------+--------------------+-----------+--------+-------+\n",
      "|  1002|     Aarav|Shrivastava|Abhyankar street|shree Palace Apar...|   Dhantoli|  Nagpur| 440012|\n",
      "|  1006|     Manoj|Shrivastava|     Mandir Road|   C-23 Kachnar City|Vijay Nagar|Jabalpur| 440057|\n",
      "|  1009|     Kiaan|Shrivastava|Abhyankar street|shree Palace Apar...|   Dhantoli|  Mumbai| 442012|\n",
      "|  1010|   Paridhi|Shrivastava|Abhyankar street|shree Palace Apar...|   Dhantoli|  Jaipur| 443012|\n",
      "+------+----------+-----------+----------------+--------------------+-----------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_add.filter(df_add.Surname.like('Shri%')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------+----------------+--------------------+-----------+------+-------+\n",
      "|Emp_Id|First_name|Surname|          Street|           Apartment|     Suburb|  City|ZipCode|\n",
      "+------+----------+-------+----------------+--------------------+-----------+------+-------+\n",
      "|  1005|   Shalini|  Singh|        Vip Road|    Daya kunj bangla|   MP Nagar|Bhopal| 410256|\n",
      "|  1007|        MS|  Dhoni|Abhyankar street|shree Palace Apar...|Dhant Nagar|Ranchi| 440612|\n",
      "+------+----------+-------+----------------+--------------------+-----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_add.filter(df_add.Surname.isin('Dhoni','Singh')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------+----------------+--------------------+------------+---------+-------+-------------------+\n",
      "|Emp_Id|First_name|    Surname|          Street|           Apartment|      Suburb|     City|ZipCode|          Full Name|\n",
      "+------+----------+-----------+----------------+--------------------+------------+---------+-------+-------------------+\n",
      "|  1001|     Rahul|    Tewatia|220 Bapat street|   Radhika Apartment|       Wakad|     Pune| 311057|      Rahul Tewatia|\n",
      "|  1002|     Aarav|Shrivastava|Abhyankar street|shree Palace Apar...|    Dhantoli|   Nagpur| 440012|  Aarav Shrivastava|\n",
      "|  1003|   Harshad|     Badani|Abhyankar street|     shree Apartment|    Dhantoli|   Nagpur| 440012|     Harshad Badani|\n",
      "|  1004|    Deepak|     Saxena|    Anand street|    Mangal Apartment|Rohini Nagar|     Kota| 450112|      Deepak Saxena|\n",
      "|  1005|   Shalini|      Singh|        Vip Road|    Daya kunj bangla|    MP Nagar|   Bhopal| 410256|      Shalini Singh|\n",
      "|  1006|     Manoj|Shrivastava|     Mandir Road|   C-23 Kachnar City| Vijay Nagar| Jabalpur| 440057|  Manoj Shrivastava|\n",
      "|  1007|        MS|      Dhoni|Abhyankar street|shree Palace Apar...| Dhant Nagar|   Ranchi| 440612|           MS Dhoni|\n",
      "|  1008|      Setu|   Upadhyay|   Zuzuvadi Road|      Zolo Hibiscous|  BTM Layout|Bangalore| 441012|      Setu Upadhyay|\n",
      "|  1009|     Kiaan|Shrivastava|Abhyankar street|shree Palace Apar...|    Dhantoli|   Mumbai| 442012|  Kiaan Shrivastava|\n",
      "|  1010|   Paridhi|Shrivastava|Abhyankar street|shree Palace Apar...|    Dhantoli|   Jaipur| 443012|Paridhi Shrivastava|\n",
      "+------+----------+-----------+----------------+--------------------+------------+---------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_add.withColumn('Full Name',F.concat(df_add['First_name'],F.lit(' '),df_add.Surname)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------+-------------+--------------------+------------+---------+-------+\n",
      "|Emp_Id|First_name|    Surname|       Street|           Apartment|      Suburb|     City|ZipCode|\n",
      "+------+----------+-----------+-------------+--------------------+------------+---------+-------+\n",
      "|  1001|     Rahul|    Tewatia| 220 Bapat st|   Radhika Apartment|       Wakad|     Pune| 311057|\n",
      "|  1002|     Aarav|Shrivastava| Abhyankar st|shree Palace Apar...|    Dhantoli|   Nagpur| 440012|\n",
      "|  1003|   Harshad|     Badani| Abhyankar st|     shree Apartment|    Dhantoli|   Nagpur| 440012|\n",
      "|  1004|    Deepak|     Saxena|     Anand st|    Mangal Apartment|Rohini Nagar|     Kota| 450112|\n",
      "|  1005|   Shalini|      Singh|     Vip Road|    Daya kunj bangla|    MP Nagar|   Bhopal| 410256|\n",
      "|  1006|     Manoj|Shrivastava|  Mandir Road|   C-23 Kachnar City| Vijay Nagar| Jabalpur| 440057|\n",
      "|  1007|        MS|      Dhoni| Abhyankar st|shree Palace Apar...| Dhant Nagar|   Ranchi| 440612|\n",
      "|  1008|      Setu|   Upadhyay|Zuzuvadi Road|      Zolo Hibiscous|  BTM Layout|Bangalore| 441012|\n",
      "|  1009|     Kiaan|Shrivastava| Abhyankar st|shree Palace Apar...|    Dhantoli|   Mumbai| 442012|\n",
      "|  1010|   Paridhi|Shrivastava| Abhyankar st|shree Palace Apar...|    Dhantoli|   Jaipur| 443012|\n",
      "+------+----------+-----------+-------------+--------------------+------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_add.withColumn('Street',F.regexp_replace('Street','street','st')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------+----------------+--------------------+------------+---------+-------+\n",
      "|Emp_Id|First_name|    Surname|          Street|           Apartment|      Suburb|     City|ZipCode|\n",
      "+------+----------+-----------+----------------+--------------------+------------+---------+-------+\n",
      "|  1001|     Rahul|    Tewatia|220 Bapat street|   Radhika Apartment|       Wakad|     Pune| 311057|\n",
      "|  1002|     Aarav|Shrivastava|Abhyankar street|shree Palace Apar...|    Dhantoli|   Nagpur| 440012|\n",
      "|  1003|   Harshad|     Badani|Abhyankar street|     shree Apartment|    Dhantoli|   Nagpur| 440012|\n",
      "|  1004|    Deepak|     Saxena|    Anand street|    Mangal Apartment|Rohini Nagar|     Kota| 450112|\n",
      "|  1005|   Shalini|      Singh|        Vip Road|    Daya kunj bangla|    MP Nagar|   Bhopal| 410256|\n",
      "|  1006|     Manoj|Shrivastava|     Mandir Road|   C-23 Kachnar City| Vijay Nagar| Jabalpur| 440057|\n",
      "|  1007|        MS|      Dhoni|Abhyankar street|shree Palace Apar...| Dhant Nagar|   Ranchi| 440612|\n",
      "|  1008|      Setu|   Upadhyay|   Zuzuvadi Road|      Zolo Hibiscous|  BTM Layout|Bangalore| 441012|\n",
      "|  1009|     Kiaan|Shrivastava|Abhyankar street|shree Palace Apar...|    Dhantoli|   Mumbai| 442012|\n",
      "|  1010|   Paridhi|Shrivastava|Abhyankar street|shree Palace Apar...|    Dhantoli|   Jaipur| 443012|\n",
      "+------+----------+-----------+----------------+--------------------+------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_add.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------+----------------+--------------------+------------+---------+-------+\n",
      "|Emp_Id|First_name|    Surname|          Street|           Apartment|      Suburb|     City|ZipCode|\n",
      "+------+----------+-----------+----------------+--------------------+------------+---------+-------+\n",
      "|  1001|     Rahul|    Tewatia|220 Bapat street|   radhika apartment|       Wakad|     Pune| 311057|\n",
      "|  1002|     Aarav|Shrivastava|Abhyankar street|SHRI palace apart...|    Dhantoli|   Nagpur| 440012|\n",
      "|  1003|   Harshad|     Badani|Abhyankar street|      SHRI apartment|    Dhantoli|   Nagpur| 440012|\n",
      "|  1004|    Deepak|     Saxena|    Anand street|    mangal apartment|Rohini Nagar|     Kota| 450112|\n",
      "|  1005|   Shalini|      Singh|        Vip Road|    daya kunj bangla|    MP Nagar|   Bhopal| 410256|\n",
      "|  1006|     Manoj|Shrivastava|     Mandir Road|   c-23 kachnar city| Vijay Nagar| Jabalpur| 440057|\n",
      "|  1007|        MS|      Dhoni|Abhyankar street|SHRI palace apart...| Dhant Nagar|   Ranchi| 440612|\n",
      "|  1008|      Setu|   Upadhyay|   Zuzuvadi Road|      zolo hibiscous|  BTM Layout|Bangalore| 441012|\n",
      "|  1009|     Kiaan|Shrivastava|Abhyankar street|SHRI palace apart...|    Dhantoli|   Mumbai| 442012|\n",
      "|  1010|   Paridhi|Shrivastava|Abhyankar street|SHRI palace apart...|    Dhantoli|   Jaipur| 443012|\n",
      "+------+----------+-----------+----------------+--------------------+------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_add.withColumn('Apartment',F.regexp_replace(F.lower(df_add['Apartment']),'shree','SHRI')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
